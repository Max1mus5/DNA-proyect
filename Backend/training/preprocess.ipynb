{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "83aac18d-b2cf-42dd-8c8a-35a2656ec9f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import chardet\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns #libreria para visualização de gráficos\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a97cbe6",
   "metadata": {},
   "source": [
    "# Charge and Exploration of the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4100070b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(file_path):\n",
    "    \"\"\"\n",
    "    Loads the data from a CSV file and performs an initial exploration.\n",
    "    \n",
    "    Args:\n",
    "    file_path (str): Path to the CSV file containing the data.\n",
    "    \n",
    "    Returns:\n",
    "    pd.DataFrame: DataFrame with the loaded data.\n",
    "    \"\"\"\n",
    "    # Detect file encoding\n",
    "    with open(file_path, 'rb') as file:\n",
    "        raw_data = file.read()\n",
    "        result = chardet.detect(raw_data)\n",
    "        encoding = result['encoding']\n",
    "\n",
    "    print(f\"Detected file encoding: {encoding}\")\n",
    "\n",
    "    try:\n",
    "        # Try to read the file with the detected encoding\n",
    "        data = pd.read_csv(file_path, encoding=encoding)\n",
    "    except UnicodeDecodeError:\n",
    "        print(\"Error with detected encoding. Trying 'latin-1' encoding...\")\n",
    "        try:\n",
    "            # If that fails, try 'latin-1' encoding\n",
    "            data = pd.read_csv(file_path, encoding='latin-1')\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading the file: {e}\")\n",
    "            return None\n",
    "\n",
    "    print(\"Dataset dimensions:\", data.shape)\n",
    "    print(\"\\nFirst 5 rows of the dataset:\")\n",
    "    print(data.head())\n",
    "    print(\"\\nDataset information:\")\n",
    "    print(data.info())\n",
    "    print(\"\\nDescriptive statistics:\")\n",
    "    print(data.describe())\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c2fd072",
   "metadata": {},
   "source": [
    "## Reading genome.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d038a15c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_data('.\\csv\\genomeTrainDisease.csv')\n",
    "\n",
    "if data is not None:\n",
    "    # Continúa con el procesamiento de los datos\n",
    "    pass\n",
    "else:\n",
    "    print(\"No se pudieron cargar los datos. Por favor, verifica el archivo y su codificación.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6d824a6",
   "metadata": {},
   "source": [
    "# Data Preprocesing\n",
    "## Cleaning the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86b908d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_data(data):\n",
    "    \"\"\"\n",
    "    Cleans the data by handling missing values and verifying the distribution.\n",
    "    \n",
    "    Args:\n",
    "    data (pd.DataFrame): Original DataFrame.\n",
    "    \n",
    "    Returns:\n",
    "    pd.DataFrame: Cleaned DataFrame.\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"Missing values for columns:\")\n",
    "    print(data.isnull().sum())\n",
    "\n",
    "    # Handle missing values for numeric columns\n",
    "    numeric_columns = data.select_dtypes(include=['int64', 'float64']).columns\n",
    "    if len(numeric_columns) > 0:\n",
    "        numeric_imputer = SimpleImputer(strategy='mean')\n",
    "        data[numeric_columns] = numeric_imputer.fit_transform(data[numeric_columns])\n",
    "\n",
    "    # Handle missing values for categorical columns (including 'genotype')\n",
    "    categorical_columns = data.select_dtypes(include=['object']).columns\n",
    "    if len(categorical_columns) > 0:\n",
    "        categorical_imputer = SimpleImputer(strategy='most_frequent')\n",
    "        data[categorical_columns] = categorical_imputer.fit_transform(data[categorical_columns])\n",
    "\n",
    "    print(\"\\nDistribution of genotypes:\")\n",
    "    print(data['genotype'].value_counts(normalize=True))\n",
    "\n",
    "    # Check for any remaining missing values\n",
    "    print(\"\\nRemaining missing values:\")\n",
    "    print(data.isnull().sum())\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "data_clean = clean_data(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf74d4ec",
   "metadata": {},
   "source": [
    "## Processing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31928bf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(data):\n",
    "    \"\"\"\n",
    "    Realiza el preprocesamiento de los datos, incluyendo codificación one-hot y escalado.\n",
    "    \n",
    "    Args:\n",
    "    data (pd.DataFrame): DataFrame limpio.\n",
    "    \n",
    "    Returns:\n",
    "    tuple: X_processed (features procesadas), preprocessor (ColumnTransformer)\n",
    "    \"\"\"\n",
    "    print(\"Iniciando preprocesamiento...\")\n",
    "    print(\"Columnas en el DataFrame:\", data.columns)\n",
    "    print(\"Tipos de datos:\")\n",
    "    print(data.dtypes)\n",
    "    \n",
    "    # Crear preprocesador\n",
    "    numeric_features = ['chromosome', 'position']\n",
    "    categorical_features = ['genotype']\n",
    "    \n",
    "    print(\"Características numéricas:\", numeric_features)\n",
    "    print(\"Características categóricas:\", categorical_features)\n",
    "    \n",
    "    # Convertir 'chromosome' y 'position' a tipo numérico si no lo son\n",
    "    data['chromosome'] = pd.to_numeric(data['chromosome'], errors='coerce')\n",
    "    data['position'] = pd.to_numeric(data['position'], errors='coerce')\n",
    "    \n",
    "    numeric_transformer = Pipeline(steps=[\n",
    "        ('imputer', SimpleImputer(strategy='median')),\n",
    "        ('scaler', StandardScaler())\n",
    "    ])\n",
    "    \n",
    "    categorical_transformer = Pipeline(steps=[\n",
    "        ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
    "        ('onehot', OneHotEncoder(drop='first', sparse_output=False))\n",
    "    ])\n",
    "    \n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('num', numeric_transformer, numeric_features),\n",
    "            ('cat', categorical_transformer, categorical_features)\n",
    "        ])\n",
    "    \n",
    "    print(\"Aplicando preprocesamiento...\")\n",
    "    # Ajustar y transformar\n",
    "    try:\n",
    "        X_processed = preprocessor.fit_transform(data)\n",
    "        print(\"Preprocesamiento completado con éxito.\")\n",
    "    except Exception as e:\n",
    "        print(\"Error durante el preprocesamiento:\")\n",
    "        print(str(e))\n",
    "        raise\n",
    "    \n",
    "    print(\"Obteniendo nombres de características...\")\n",
    "    # Obtener nombres de características después del preprocesamiento\n",
    "    onehot_encoder = preprocessor.named_transformers_['cat'].named_steps['onehot']\n",
    "    feature_names = (numeric_features + \n",
    "                     onehot_encoder.get_feature_names_out(categorical_features).tolist())\n",
    "    \n",
    "    X_processed_df = pd.DataFrame(X_processed, columns=feature_names)\n",
    "    \n",
    "    print(\"Dimensiones de X después del preprocesamiento:\", X_processed_df.shape)\n",
    "    print(\"\\nPrimeras 5 filas de X preprocesado:\")\n",
    "    print(X_processed_df.head())\n",
    "    \n",
    "    return X_processed_df, preprocessor\n",
    "\n",
    "# Aplicar\n",
    "try:\n",
    "    X_processed, preprocessor = preprocess_data(data_clean)\n",
    "    print(\"Preprocesamiento completado exitosamente.\")\n",
    "except Exception as e:\n",
    "    print(\"Error al aplicar el preprocesamiento:\")\n",
    "    print(str(e))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abab2b06",
   "metadata": {},
   "source": [
    "# Vizualice data cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d5f439a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "def visualize_data(data):\n",
    "    \"\"\"\n",
    "    Creates visualizations to explore the genomic data.\n",
    "    \n",
    "    Args:\n",
    "    data (pd.DataFrame): DataFrame with columns: rsid, chromosome, position, genotype, magnitude, reputation, summary\n",
    "    \"\"\"\n",
    "    \n",
    "    # Set the style for better-looking plots\n",
    "    sns.set_style(\"whitegrid\")\n",
    "    \n",
    "    # 1. Distribution of Genotypes\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    sns.countplot(x='genotype', data=data)\n",
    "    plt.title('Distribution of Genotypes')\n",
    "    plt.xlabel('Genotype')\n",
    "    plt.ylabel('Count')\n",
    "    plt.show()\n",
    "    \n",
    "    # 2. Distribution of Chromosomes\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    chromosome_counts = data['chromosome'].value_counts().sort_index()\n",
    "    sns.barplot(x=chromosome_counts.index, y=chromosome_counts.values)\n",
    "    plt.title('Distribution of SNPs across Chromosomes')\n",
    "    plt.xlabel('Chromosome')\n",
    "    plt.ylabel('Number of SNPs')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.show()\n",
    "    \n",
    "    # 3. Genotype Distribution by Chromosome\n",
    "    plt.figure(figsize=(15, 8))\n",
    "    sns.countplot(x='chromosome', hue='genotype', data=data)\n",
    "    plt.title('Genotype Distribution by Chromosome')\n",
    "    plt.xlabel('Chromosome')\n",
    "    plt.ylabel('Count')\n",
    "    plt.legend(title='Genotype', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # 4. Position Distribution by Chromosome\n",
    "    plt.figure(figsize=(15, 8))\n",
    "    sns.boxplot(x='chromosome', y='position', data=data)\n",
    "    plt.title('Distribution of Positions by Chromosome')\n",
    "    plt.xlabel('Chromosome')\n",
    "    plt.ylabel('Position')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.show()\n",
    "    \n",
    "    # 5. Scatter plot of Position vs Magnitude (if available)\n",
    "    if 'magnitude' in data.columns and data['magnitude'].notna().any():\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        sns.scatterplot(data=data, x='position', y='magnitude', hue='chromosome')\n",
    "        plt.title('Position vs Magnitude by Chromosome')\n",
    "        plt.xlabel('Position')\n",
    "        plt.ylabel('Magnitude')\n",
    "        plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "        plt.show()\n",
    "\n",
    "visualize_data(data_clean)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96581233",
   "metadata": {},
   "source": [
    "# Correlation Analisis of numeric features\n",
    "## Importance of Correlation Analysis\n",
    "\n",
    "El análisis de correlación es crucial en el preprocesamiento de datos y el análisis exploratorio de datos (AED). Ayuda a:\n",
    "\n",
    "1. **Identificar relaciones**: Comprender la relación entre las características numéricas puede ayudar a mejorar el rendimiento del modelo al resaltar qué características están correlacionadas positiva o negativamente.\n",
    "2. 2. **Selección de características**: Las características muy correlacionadas pueden proporcionar información redundante. La eliminación de tales características puede reducir la complejidad del modelo sin perder mucha información.\n",
    "3. **Detección de multicolinealidad**: En los modelos de regresión, la multicolinealidad (cuando dos o más predictores están altamente correlacionados) puede hacer que las estimaciones de los parámetros sean inestables e inflar los errores estándar. La detección temprana de la multicolinealidad permite realizar los ajustes oportunos.\n",
    "\n",
    "## Performing Correlation Analysis\n",
    "Para realizar un análisis de correlación entre características numéricas, siga estos pasos:\n",
    "\n",
    "1. **Seleccionar características numéricas**: En este caso, seleccionamos 'cromosoma' y 'posición' del conjunto de datos.\n",
    " 2. **Calcular la matriz de correlación**: Utilizar el método `corr()` proporcionado por pandas para calcular la matriz de correlaciones, que muestra los coeficientes de correlación entre pares de características.\n",
    "3. **Visualizar Correlación**: Se genera un mapa de calor utilizando la función `heatmap()` de seaborn. Esta representación visual ayuda a identificar rápidamente los patrones de correlación y la fuerza de las relaciones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ba41e62",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "def analyze_correlation(data):\n",
    "    \"\"\"\n",
    "    Performs a correlation analysis among numeric features and clustering analysis based on magnitude.\n",
    "    \n",
    "    Args:\n",
    "    data (pd.DataFrame): DataFrame with columns including chromosome, position, magnitude\n",
    "    \"\"\"\n",
    "    # Create a clean copy of the data\n",
    "    clean_data = data.copy()\n",
    "    \n",
    "    # Convert chromosome to numeric, replacing non-numeric values with NaN\n",
    "    clean_data['chromosome'] = pd.to_numeric(clean_data['chromosome'], errors='coerce')\n",
    "    \n",
    "    # Convert magnitude to numeric, replacing non-numeric values with NaN\n",
    "    clean_data['magnitude'] = pd.to_numeric(clean_data['magnitude'], errors='coerce')\n",
    "    \n",
    "    # Remove rows where either chromosome or magnitude is NaN, infinite, or undefined\n",
    "    clean_data = clean_data.replace([np.inf, -np.inf], np.nan)\n",
    "    clean_data = clean_data.dropna(subset=['chromosome', 'magnitude'])\n",
    "    \n",
    "    if len(clean_data) == 0:\n",
    "        print(\"No hay datos válidos después de la limpieza\")\n",
    "        return\n",
    "        \n",
    "    # Create magnitude category (solo para valores válidos)\n",
    "    clean_data['magnitude_category'] = clean_data['magnitude'].apply(\n",
    "        lambda x: 'good' if 0 <= x <= 2.5 else 'bad' if x > 2.5 else 'undefined'\n",
    "    )\n",
    "    \n",
    "    # Traditional correlation analysis with only numeric columns\n",
    "    numeric_features = clean_data[['chromosome', 'position', 'magnitude']].copy()\n",
    "    corr_matrix = numeric_features.corr()\n",
    "    \n",
    "    try:\n",
    "        # Correlation Matrix\n",
    "        plt.figure(figsize=(10, 8))\n",
    "        sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', vmin=-1, vmax=1, center=0)\n",
    "        plt.title('Correlation Matrix of Numeric Features')\n",
    "        plt.show()\n",
    "\n",
    "        # Distribution of categories\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        valid_categories = clean_data[clean_data['magnitude_category'].isin(['good', 'bad'])]\n",
    "        sns.countplot(data=valid_categories, x='magnitude_category')\n",
    "        plt.title('Distribution of Magnitude Categories')\n",
    "        plt.show()\n",
    "\n",
    "        # Prepare data for k-means\n",
    "        X = clean_data[['chromosome', 'magnitude']].copy()\n",
    "        \n",
    "        # Additional verification for any remaining NaN values\n",
    "        X = X.dropna()\n",
    "        \n",
    "        if len(X) < 3:\n",
    "            print(\"No hay suficientes datos válidos para clustering\")\n",
    "            return\n",
    "            \n",
    "        # Scale the features\n",
    "        scaler = StandardScaler()\n",
    "        X_scaled = scaler.fit_transform(X)\n",
    "        \n",
    "        # Determine optimal number of clusters\n",
    "        max_k = min(10, len(X))\n",
    "        if max_k > 1:\n",
    "            inertias = []\n",
    "            K = range(1, max_k)\n",
    "            for k in K:\n",
    "                kmeans = KMeans(n_clusters=k, random_state=42)\n",
    "                kmeans.fit(X_scaled)\n",
    "                inertias.append(kmeans.inertia_)\n",
    "            \n",
    "            # Plot elbow curve\n",
    "            plt.figure(figsize=(10, 6))\n",
    "            plt.plot(K, inertias, 'bx-')\n",
    "            plt.xlabel('k')\n",
    "            plt.ylabel('Inertia')\n",
    "            plt.title('Elbow Method For Optimal k')\n",
    "            plt.show()\n",
    "            \n",
    "            # Perform clustering\n",
    "            optimal_k = min(3, len(X)-1)\n",
    "            kmeans = KMeans(n_clusters=optimal_k, random_state=42)\n",
    "            X['Cluster'] = kmeans.fit_predict(X_scaled)\n",
    "            \n",
    "            # Visualize clusters\n",
    "            plt.figure(figsize=(12, 8))\n",
    "            scatter = plt.scatter(X['chromosome'], \n",
    "                                X['magnitude'],\n",
    "                                c=X['Cluster'], \n",
    "                                cmap='viridis')\n",
    "            plt.xlabel('Chromosome')\n",
    "            plt.ylabel('Magnitude')\n",
    "            plt.title('K-means Clustering of Chromosome vs Magnitude')\n",
    "            plt.colorbar(scatter, label='Cluster')\n",
    "            plt.show()\n",
    "            \n",
    "            # Print statistics\n",
    "            print(\"\\nCluster Statistics:\")\n",
    "            cluster_stats = X.groupby('Cluster').agg({\n",
    "                'magnitude': ['mean', 'std', 'count'],\n",
    "                'chromosome': ['mean', 'nunique']\n",
    "            }).round(2)\n",
    "            print(cluster_stats)\n",
    "\n",
    "        # Additional visualization: Magnitude distribution\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        sns.histplot(data=X, x='magnitude', bins=30)\n",
    "        plt.title('Distribution of Magnitude Values')\n",
    "        plt.axvline(x=2.5, color='r', linestyle='--', label='Category Threshold')\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "\n",
    "        # Print summary statistics\n",
    "        print(\"\\nSummary of clean data:\")\n",
    "        print(f\"Total rows processed: {len(data)}\")\n",
    "        print(f\"Rows with valid data: {len(X)}\")\n",
    "        print(f\"Rows removed due to missing/invalid data: {len(data) - len(X)}\")\n",
    "        print(\"\\nMagnitude statistics:\")\n",
    "        print(X['magnitude'].describe().round(3))\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Se produjo un error durante el análisis: {str(e)}\")\n",
    "        print(\"Datos disponibles para diagnóstico:\")\n",
    "        print(f\"Número de filas en clean_data: {len(clean_data)}\")\n",
    "        print(f\"Columnas disponibles: {clean_data.columns.tolist()}\")\n",
    "        print(\"Muestra de los primeros registros válidos:\")\n",
    "        print(clean_data.head())\n",
    "        print(\"\\nResumen estadístico:\")\n",
    "        print(clean_data.describe())\n",
    "\n",
    "analyze_correlation(data_clean)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f9bf0c9",
   "metadata": {},
   "source": [
    "- Paso 1**: Extrae datos numéricos de las columnas 'cromosoma' y 'posición'.\n",
    "- Paso 2**: Calcula la matriz de correlaciones utilizando el método `corr()` de pandas.\n",
    "- Paso 3**: Traza la matriz de correlación usando `heatmap()` de seaborn, donde:\n",
    "  - `annot=True` muestra los coeficientes de correlación.\n",
    "  - `cmap='coolwarm'` especifica el mapa de colores.\n",
    "  - vmin=-1` y `vmax=1` establecen el rango de la escala de color.\n",
    "  - `center=0` asegura que el mapa de color está centrado alrededor de cero.\n",
    "\n",
    "facilitamos de esta forma la interpretación de los resultados."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "463ba661",
   "metadata": {},
   "source": [
    "# SNPs distribution by Chromosome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "609895a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_snp_distribution(data):\n",
    "    \"\"\"\n",
    "    Analyzes the distribution of SNPs across chromosomes and their characteristics.\n",
    "    \n",
    "    Args:\n",
    "    data (pd.DataFrame): DataFrame with columns: rsid, chromosome, position, genotype, magnitude, reputation, summary\n",
    "    \n",
    "    Returns:\n",
    "    pd.DataFrame: Summary statistics by chromosome\n",
    "    \"\"\"\n",
    "    # Use a simple style\n",
    "    plt.style.use('default')\n",
    "    \n",
    "    # 1. SNP Distribution Plot\n",
    "    snp_counts = data['chromosome'].value_counts().sort_index()\n",
    "    \n",
    "    plt.figure(figsize=(15, 6))\n",
    "    ax = sns.barplot(x=snp_counts.index, y=snp_counts.values)\n",
    "    plt.title('Distribución de SNPs por Cromosoma')\n",
    "    plt.xlabel('Cromosoma')\n",
    "    plt.ylabel('Número de SNPs')\n",
    "    plt.xticks(rotation=0)\n",
    "    \n",
    "    # Add value labels on top of each bar\n",
    "    for i, v in enumerate(snp_counts.values):\n",
    "        ax.text(i, v, str(v), ha='center', va='bottom')\n",
    "    plt.show()\n",
    "\n",
    "    # 2. Genotype Distribution by Chromosome\n",
    "    plt.figure(figsize=(15, 6))\n",
    "    genotype_dist = pd.crosstab(data['chromosome'], data['genotype'], normalize='index') * 100\n",
    "    genotype_dist.plot(kind='bar', stacked=True)\n",
    "    plt.title('Distribución de Genotipos por Cromosoma (%)')\n",
    "    plt.xlabel('Cromosoma')\n",
    "    plt.ylabel('Porcentaje')\n",
    "    plt.legend(title='Genotipos')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # 3. Generate Summary Statistics\n",
    "    summary = summarize_by_chromosome(data)\n",
    "    return summary\n",
    "\n",
    "def summarize_by_chromosome(data):\n",
    "    \"\"\"\n",
    "    Generates a comprehensive summary of SNPs by chromosome\n",
    "    \n",
    "    Args:\n",
    "    data (pd.DataFrame): DataFrame with genomic data\n",
    "    \n",
    "    Returns:\n",
    "    pd.DataFrame: Detailed summary statistics by chromosome\n",
    "    \"\"\"\n",
    "    # Basic position statistics\n",
    "    summary = data.groupby('chromosome').agg({\n",
    "        'position': ['count', 'min', 'max', 'mean', 'median', 'std'],\n",
    "        'genotype': lambda x: x.value_counts().index[0]  # Most common genotype\n",
    "    }).round(2)\n",
    "    \n",
    "    # Calculate density (SNPs per million base pairs)\n",
    "    summary['density'] = (summary['position']['count'] / \n",
    "                         ((summary['position']['max'] - summary['position']['min']) / 1_000_000)).round(2)\n",
    "    \n",
    "    # Flatten column names and rename\n",
    "    summary.columns = [\n",
    "        'Número de SNPs',\n",
    "        'Posición Mínima',\n",
    "        'Posición Máxima',\n",
    "        'Posición Media',\n",
    "        'Posición Mediana',\n",
    "        'Desviación Estándar',\n",
    "        'Genotipo más común',\n",
    "        'Densidad (SNPs/Mb)'\n",
    "    ]\n",
    "    \n",
    "    # Reset index and rename chromosome column\n",
    "    summary = summary.reset_index().rename(columns={'chromosome': 'Cromosoma'})\n",
    "    \n",
    "    # Add spacing for better printing\n",
    "    pd.set_option('display.max_columns', None)\n",
    "    pd.set_option('display.width', None)\n",
    "    \n",
    "    return summary\n",
    "\n",
    "summary = analyze_snp_distribution(data_clean)\n",
    "print(\"\\nResumen estadístico por cromosoma:\")\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0335807a",
   "metadata": {},
   "source": [
    "# Save Preprocessed Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2048c428",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from datetime import datetime\n",
    "import os\n",
    "\n",
    "def save_processed_data(data, output_directory='./processed_data'):\n",
    "    \"\"\"\n",
    "    Saves the preprocessed data and generates a comprehensive analysis report.\n",
    "    \n",
    "    Args:\n",
    "    data (pd.DataFrame): DataFrame with preprocessed data.\n",
    "    output_directory (str): Directory where the files will be saved.\n",
    "    \"\"\"\n",
    "    # Create output directory if it doesn't exist\n",
    "    os.makedirs(output_directory, exist_ok=True)\n",
    "    \n",
    "    # Generate timestamp for file names\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    \n",
    "    # 1. Save processed data\n",
    "    data_filename = os.path.join(output_directory, f'processed_genetic_data_{timestamp}.csv')\n",
    "    data.to_csv(data_filename, index=False)\n",
    "    print(f\"\\nProcesamiento completado. Datos guardados en: {data_filename}\")\n",
    "    \n",
    "    # 2. Generate and save analysis summary\n",
    "    summary_filename = os.path.join(output_directory, f'analysis_summary_{timestamp}.txt')\n",
    "    \n",
    "    with open(summary_filename, 'w', encoding='utf-8') as f:\n",
    "        f.write(\"RESUMEN DEL ANÁLISIS GENÓMICO\\n\")\n",
    "        f.write(\"=\" * 50 + \"\\n\\n\")\n",
    "        \n",
    "        # Basic dataset information\n",
    "        f.write(\"1. INFORMACIÓN GENERAL\\n\")\n",
    "        f.write(\"-\" * 20 + \"\\n\")\n",
    "        f.write(f\"Fecha de análisis: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\\n\")\n",
    "        f.write(f\"Número total de SNPs: {len(data)}\\n\")\n",
    "        f.write(f\"Número de cromosomas únicos: {data['chromosome'].nunique()}\\n\")\n",
    "        f.write(f\"Número de genotipos únicos: {data['genotype'].nunique()}\\n\\n\")\n",
    "        \n",
    "        # Chromosome statistics\n",
    "        f.write(\"2. ESTADÍSTICAS POR CROMOSOMA\\n\")\n",
    "        f.write(\"-\" * 20 + \"\\n\")\n",
    "        chromosome_stats = data.groupby('chromosome').agg({\n",
    "            'rsid': 'count',\n",
    "            'position': ['min', 'max', 'mean']\n",
    "        })\n",
    "        f.write(chromosome_stats.to_string())\n",
    "        f.write(\"\\n\\n\")\n",
    "        \n",
    "        # Genotype distribution\n",
    "        f.write(\"3. DISTRIBUCIÓN DE GENOTIPOS\\n\")\n",
    "        f.write(\"-\" * 20 + \"\\n\")\n",
    "        genotype_dist = data['genotype'].value_counts()\n",
    "        f.write(genotype_dist.to_string())\n",
    "        f.write(\"\\n\\n\")\n",
    "        \n",
    "        # Data quality metrics\n",
    "        f.write(\"4. MÉTRICAS DE CALIDAD DE DATOS\\n\")\n",
    "        f.write(\"-\" * 20 + \"\\n\")\n",
    "        missing_values = data.isnull().sum()\n",
    "        f.write(f\"Valores faltantes por columna:\\n{missing_values.to_string()}\\n\\n\")\n",
    "        \n",
    "        # Additional information (if available)\n",
    "        if 'magnitude' in data.columns and 'reputation' in data.columns:\n",
    "            f.write(\"5. INFORMACIÓN ADICIONAL\\n\")\n",
    "            f.write(\"-\" * 20 + \"\\n\")\n",
    "            f.write(\"Estadísticas de magnitud y reputación:\\n\")\n",
    "            additional_stats = data[['magnitude', 'reputation']].describe()\n",
    "            f.write(additional_stats.to_string())\n",
    "            f.write(\"\\n\\n\")\n",
    "        \n",
    "        # KMeans clustering and elbow method for optimal k\n",
    "        f.write(\"6. CLUSTERING KMEANS\\n\")\n",
    "        f.write(\"-\" * 20 + \"\\n\")\n",
    "        \n",
    "        # Prepare data for KMeans\n",
    "        X = data[['chromosome', 'magnitude']].copy().dropna()\n",
    "        \n",
    "        # Scale the features\n",
    "        scaler = StandardScaler()\n",
    "        X_scaled = scaler.fit_transform(X)\n",
    "        \n",
    "        # Elbow method to determine optimal number of clusters\n",
    "        max_k = min(10, len(X))\n",
    "        inertias = []\n",
    "        K = range(1, max_k)\n",
    "        \n",
    "        for k in K:\n",
    "            kmeans = KMeans(n_clusters=k, random_state=42)\n",
    "            kmeans.fit(X_scaled)\n",
    "            inertias.append(kmeans.inertia_)\n",
    "        \n",
    "        # Plot elbow curve and save it\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.plot(K, inertias, 'bx-')\n",
    "        plt.xlabel('k')\n",
    "        plt.ylabel('Inertia')\n",
    "        plt.title('Elbow Method For Optimal k')\n",
    "        elbow_plot_filename = os.path.join(output_directory, f'elbow_plot_{timestamp}.png')\n",
    "        plt.savefig(elbow_plot_filename)\n",
    "        plt.close()\n",
    "        f.write(f\"Elbow plot guardado en: {elbow_plot_filename}\\n\")\n",
    "        \n",
    "        # Determine optimal k using elbow method (finding the elbow point)\n",
    "        optimal_k = 3  # For example purposes; should be determined dynamically based on the elbow\n",
    "        f.write(f\"Número óptimo de clusters (K): {optimal_k}\\n\\n\")\n",
    "        \n",
    "        # Perform KMeans clustering\n",
    "        kmeans = KMeans(n_clusters=optimal_k, random_state=42)\n",
    "        X['Cluster'] = kmeans.fit_predict(X_scaled)\n",
    "        \n",
    "        # Cluster statistics\n",
    "        cluster_stats = X.groupby('Cluster').agg({\n",
    "            'magnitude': ['mean', 'std', 'count'],\n",
    "            'chromosome': ['mean', 'nunique']\n",
    "        }).round(2)\n",
    "        f.write(\"Estadísticas por cluster:\\n\")\n",
    "        f.write(cluster_stats.to_string())\n",
    "        f.write(\"\\n\\n\")\n",
    "    \n",
    "    print(f\"Resumen del análisis guardado en: {summary_filename}\")\n",
    "    \n",
    "    # 3. Save data statistics in JSON format for potential programmatic use\n",
    "    stats_filename = os.path.join(output_directory, f'data_statistics_{timestamp}.json')\n",
    "    \n",
    "    statistics = {\n",
    "        \"dataset_info\": {\n",
    "            \"total_snps\": len(data),\n",
    "            \"unique_chromosomes\": data['chromosome'].nunique(),\n",
    "            \"unique_genotypes\": data['genotype'].nunique()\n",
    "        },\n",
    "        \"genotype_distribution\": data['genotype'].value_counts().to_dict(),\n",
    "        \"chromosome_counts\": data['chromosome'].value_counts().to_dict(),\n",
    "        \"missing_values\": data.isnull().sum().to_dict(),\n",
    "        \"optimal_k\": optimal_k\n",
    "    }\n",
    "    \n",
    "    with open(stats_filename, 'w', encoding='utf-8') as f:\n",
    "        json.dump(statistics, f, ensure_ascii=False, indent=4)\n",
    "    \n",
    "    print(f\"Estadísticas detalladas guardadas en: {stats_filename}\")\n",
    "    print(\"\\nAnálisis exploratorio y preprocesamiento completados exitosamente.\")\n",
    "\n",
    "save_processed_data(data_clean, output_directory='./processed_data')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23fb9e36",
   "metadata": {},
   "source": [
    "### ¿Qué representa este conjunto de datos final?\n",
    "\n",
    "1. **Cromosoma y Posición:**\n",
    "   - Cada fila del conjunto de datos representa una **sección específica del ADN** de una persona. \n",
    "   - El **cromosoma** indica en qué parte del genoma estamos observando. Hay 23 pares de cromosomas en los humanos, y estos datos están normalizados o \"escalados\" para facilitar el procesamiento en un modelo.\n",
    "   - La **posición** indica el lugar exacto dentro del cromosoma donde estamos observando una variación genética importante, también escalada.\n",
    "\n",
    "2. **Genotipos:**\n",
    "   - Cada persona hereda una combinación de ADN de sus padres, y cada sección de ADN puede contener diferentes combinaciones de \"letras\" (A, C, G, T, que son las bases del ADN).\n",
    "   - En este conjunto de datos, los **genotipos** (o combinaciones genéticas) están codificados de una manera que las computadoras pueden entender fácilmente, usando lo que se llama **one-hot encoding**. Básicamente, una columna para cada posible combinación de letras (AA, AG, CC, GT, etc.), y se marca un **1** si esa combinación está presente o un **0** si no lo está.\n",
    "   - También hay variaciones como deleciones (cuando falta una parte del ADN, marcado como **D**) o inserciones (cuando hay ADN adicional, marcado como **I**).\n",
    "\n",
    "3. **Ejemplo de cómo interpretar una fila:**\n",
    "   - **Cromosoma:** `-1.36` (escalado, pero indica un cromosoma específico, como el 7 por ejemplo).\n",
    "   - **Posición:** `-1.35` (indica una posición específica en ese cromosoma).\n",
    "   - **Genotipo_AA:** `1.0` (esto significa que en esta posición, la persona tiene la combinación de letras \"AA\").\n",
    "   - **Genotipo_AG, GT, CC, etc.:** `0.0` (esto significa que otras combinaciones de letras no están presentes en esta posición).\n",
    "\n",
    "### ¿Por qué es importante este formato?\n",
    "\n",
    "- **Escalado de Datos Numéricos:** Los valores de cromosoma y posición están escalados para que todas las variables numéricas tengan una escala similar, lo que ayuda a que el algoritmo de machine learning no favorezca una sobre otra.\n",
    "  \n",
    "- **Codificación One-Hot:** Al codificar los genotipos en múltiples columnas con valores de 0 y 1, el modelo puede procesar estas combinaciones genéticas de manera eficiente, aprendiendo cuáles son más importantes para predecir una enfermedad.\n",
    "\n",
    "- **Permitir Variantes Genéticas Complejas:** No solo consideramos combinaciones básicas (AA, AG, etc.), sino también variantes estructurales como inserciones y deleciones, que pueden tener un impacto significativo en el desarrollo de enfermedades.\n",
    "\n",
    "Este conjunto de datos es el punto de partida para que una red neuronal o un modelo de aprendizaje automático aprenda qué combinaciones genéticas están asociadas con una enfermedad específica."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
