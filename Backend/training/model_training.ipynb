{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "83aac18d-b2cf-42dd-8c8a-35a2656ec9f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a97cbe6",
   "metadata": {},
   "source": [
    "# Charge and Exploration of the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4100070b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(file_path):\n",
    "    \"\"\"\n",
    "    Loads the data from a CSV file and performs an initial exploration.\n",
    "    \n",
    "    Args:\n",
    "    file_path (str): Path to the CSV file containing the data.\n",
    "    \n",
    "    Returns:\n",
    "    pd.DataFrame: DataFrame with the loaded data.\n",
    "    \"\"\"\n",
    "    data = pd.read_csv(file_path)\n",
    "    print(\"Dataset dimensions:\", data.shape)\n",
    "    print(\"\\nFirst 5 rows of the dataset:\")\n",
    "    print(data.head())\n",
    "    print(\"\\nDataset information:\")\n",
    "    print(data.info())\n",
    "    print(\"\\nDescriptive statistics:\")\n",
    "    print(data.describe())\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c2fd072",
   "metadata": {},
   "source": [
    "## Reading genome.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d038a15c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\JERON\\AppData\\Local\\Temp\\ipykernel_6092\\3407082076.py:11: DtypeWarning: Columns (1) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  data = pd.read_csv(file_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset dimensions: (966977, 4)\n",
      "\n",
      "First 5 rows of the dataset:\n",
      "         rsid chromosome  position genotype\n",
      "0   rs4477212          1     72017       AA\n",
      "1   rs3094315          1    742429       AA\n",
      "2   rs3131972          1    742584       GG\n",
      "3  rs12124819          1    766409       AA\n",
      "4  rs11240777          1    788822       AG\n",
      "\n",
      "Dataset information:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 966977 entries, 0 to 966976\n",
      "Data columns (total 4 columns):\n",
      " #   Column      Non-Null Count   Dtype \n",
      "---  ------      --------------   ----- \n",
      " 0   rsid        966977 non-null  object\n",
      " 1   chromosome  966977 non-null  object\n",
      " 2   position    966977 non-null  int64 \n",
      " 3   genotype    966977 non-null  object\n",
      "dtypes: int64(1), object(3)\n",
      "memory usage: 29.5+ MB\n",
      "None\n",
      "\n",
      "Descriptive statistics:\n",
      "           position\n",
      "count  9.669770e+05\n",
      "mean   7.672147e+07\n",
      "std    5.640974e+07\n",
      "min    3.000000e+00\n",
      "25%    3.012131e+07\n",
      "50%    6.667251e+07\n",
      "75%    1.134776e+08\n",
      "max    2.471856e+08\n"
     ]
    }
   ],
   "source": [
    "data = load_data('.\\genome.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6d824a6",
   "metadata": {},
   "source": [
    "# Data Preprocesing\n",
    "## Cleaning the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86b908d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_data(data):\n",
    "  \"\"\"\n",
    "  Cleans the data by handling missing values and verifying the distribution.\n",
    "  \n",
    "  Args:\n",
    "  data (pd.DataFrame): Original DataFrame.\n",
    "  \n",
    "  Returns:\n",
    "  pd.DataFrame: Cleaned DataFrame.\n",
    "  \"\"\"\n",
    "\n",
    "  print (\"missing values for columns\")\n",
    "  print(data.isnull().sum())\n",
    "\n",
    "  # Handle missing values\n",
    "  imputer = SimpleImputer(strategy='most_frequent')#used to replace missing values with the most frequent value in the column\n",
    "  data_imputed = pd.DataFrame(imputer.fit_transform(data), columns=data.columns)# data_imputed is a new dataframe with the missing values replaced\n",
    "\n",
    "  print(\"\\nDistribution of genotypes:\")\n",
    "  print(data_imputed['genotype'].value_counts(normalize=True)) #will get the percentage of each genotype\n",
    "\n",
    "  print(\"\\nDistribution of Phenotypes:\")\n",
    "  print(data_imputed['phenotype'].value_counts(normalize=True))\n",
    "    \n",
    "  return data_imputed\n",
    "data_clean = clean_data(data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf74d4ec",
   "metadata": {},
   "source": [
    "## Processing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31928bf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(data):\n",
    "  \"\"\"\n",
    "  Preprocesses the data, including one-hot encoding and scaling.\n",
    "  \n",
    "  Args:\n",
    "  data (pd.DataFrame): Cleaned DataFrame.\n",
    "  \n",
    "  Returns:\n",
    "  tuple: X (features), y (target), preprocessor (ColumnTransformer)\n",
    "  \"\"\"\n",
    "  # Separate features and target\n",
    "  X = data.drop('phenotype', axis=1)\n",
    "  y = data['phenotype']\n",
    "  \n",
    "  # Create preprocessor\n",
    "  numeric_features = ['chromosome', 'position']\n",
    "  categorical_features = ['genotype']\n",
    "  \n",
    "  preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "      ('num', StandardScaler(), numeric_features),\n",
    "      ('cat', OneHotEncoder(drop='first', sparse=False), categorical_features)\n",
    "    ])\n",
    "  \n",
    "  # Fit and transform\n",
    "  X_processed = preprocessor.fit_transform(X)\n",
    "  \n",
    "  # Get feature names after preprocessing\n",
    "  feature_names = (numeric_features + \n",
    "           preprocessor.named_transformers_['cat']\n",
    "           .get_feature_names_out(categorical_features).tolist())\n",
    "  \n",
    "  X_processed_df = pd.DataFrame(X_processed, columns=feature_names)\n",
    "  \n",
    "  print(\"Dimensions of X after preprocessing:\", X_processed_df.shape)\n",
    "  print(\"\\nFirst 5 rows of preprocessed X:\")\n",
    "  print(X_processed_df.head())\n",
    "  \n",
    "  return X_processed_df, y, preprocessor\n",
    "\n",
    "X, y, preprocessor = preprocess_data(data_clean)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abab2b06",
   "metadata": {},
   "source": [
    "# Training and Testing Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d5f439a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
